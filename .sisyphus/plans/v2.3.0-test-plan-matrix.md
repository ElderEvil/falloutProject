# v2.3.0 Test Plan Matrix

## Coverage Targets by Module

| Module | Current | Target | New Tests | Priority | Complexity |
|--------|---------|--------|-----------|----------|------------|
| middleware/security.py | 0% | 85% | 15 | HIGH | Low |
| middleware/request_id.py | 0% | 85% | 8 | HIGH | Low |
| db/session.py | 0% | 75% | 6 | HIGH | Medium |
| db/init_db.py | 0% | 75% | 10 | HIGH | Low |
| services/incident_service.py | 28% | 75% | 25 | MEDIUM | High |
| services/game_loop.py | 54% | 80% | 30 | MEDIUM | High |
| api/endpoints/room.py (unique) | ~70% | 95% | 8 | LOW | Low |

## Test Distribution

### By Type
- **Unit Tests:** 65 (middleware, db, service methods)
- **Integration Tests:** 30 (game loop phases, incident orchestration)
- **API Tests:** 8 (unique room endpoints)
- **Edge Cases:** ~15 (error handling, boundary conditions)

### By Complexity
- **Simple (1-2 hours):** 40 tests (middleware, db, unique rooms)
- **Medium (3-5 hours):** 35 tests (incident spawning, game loop phases)
- **Complex (1-2 days):** 25 tests (combat calculations, multi-phase orchestration)

## Critical Path

```
Phase 1: Datetime Fix (BLOCKING)
  â””â”€ Affects all modules, must complete first
     Estimated: 30 minutes

Phase 2 & 3: Middleware + DB (PARALLEL)
  â”œâ”€ test_middleware/ (3-4 hours)
  â””â”€ test_db/ (2-3 hours)
     Estimated: 1 day total

Phase 4: Incident Service (SEQUENTIAL)
  â””â”€ Fix session isolation first
     â”œâ”€ Session fix (1-2 hours)
     â””â”€ Add tests (4-6 hours)
        Estimated: 1 day total

Phase 5: Game Loop (SEQUENTIAL)
  â””â”€ Depends on understanding incident patterns
     Estimated: 1 day total

Phase 6: Unique Rooms (OPTIONAL)
  â””â”€ Can run anytime
     Estimated: 2-3 hours
```

## Risk Matrix

| Risk | Phase | Mitigation |
|------|-------|------------|
| Datetime changes break timestamps | 1 | Run full test suite after each file update |
| Session isolation fix causes cascade | 4 | Test one method at a time, have rollback ready |
| Game loop tests too coupled | 5 | Mock dependencies, test phases independently |
| Coverage target unrealistic | All | Prioritize critical paths, accept 75% if needed |

## Testing Strategy

### Isolation Levels
1. **Pure Unit (40%)** - Mock all dependencies
2. **Service Unit (30%)** - Real DB, mock external services  
3. **Integration (20%)** - Real DB + Redis, mock AI/MinIO
4. **API E2E (10%)** - Full stack, all dependencies mocked

### Fixture Reuse
- âœ… Reuse existing: `async_session`, `async_client`, `superuser_token_headers`
- âœ… Extend: `vault`, `dweller`, `room` fixtures
- ðŸ†• Add new: `active_incident`, `ongoing_exploration`, `training_session`

### Assertion Patterns
- State changes (DB records updated)
- Return values (correct calculations)
- Side effects (logging, notifications)
- Error handling (exceptions raised)

## Daily Breakdown

### Day 1: Foundation
- Morning: Phase 1 (Datetime) + Phase 2 (Middleware)
- Afternoon: Phase 3 (DB tests)
- **Deliverable:** 47 new tests, ~30% coverage gain

### Day 2: Complex Services
- Morning: Phase 4 (Incident service fix + tests)
- Afternoon: Phase 5 start (Game loop orchestration)
- **Deliverable:** 55+ new tests, ~20% coverage gain

### Day 3: Completion
- Morning: Phase 5 completion (Game loop phases)
- Afternoon: Phase 6 (Unique rooms) + verification
- **Deliverable:** Final tests, coverage verification, documentation

## Coverage Calculation

**Current State:**
- Total lines: ~8,000 (estimated)
- Covered: ~3,560 (44.5%)
- Uncovered: ~4,440

**Target State:**
- New coverage: ~2,840 lines (from 102 tests Ã— ~28 lines/test avg)
- Final coverage: ~6,400 / 8,000 = **80%** âœ…

**Critical Modules Impact:**
- middleware: +140 lines
- db: +120 lines
- incident_service: +350 lines
- game_loop: +450 lines
- Total: +1,060 high-value lines

## Verification Commands

```bash
# Run specific test suites
uv run pytest app/tests/test_middleware/ -v
uv run pytest app/tests/test_db/ -v  
uv run pytest app/tests/test_services/test_incident_service.py -v
uv run pytest app/tests/test_services/test_game_loop.py -v

# Coverage by module
uv run pytest --cov=app.middleware --cov-report=term-missing
uv run pytest --cov=app.db --cov-report=term-missing
uv run pytest --cov=app.services.incident_service --cov-report=term-missing
uv run pytest --cov=app.services.game_loop --cov-report=term-missing

# Full coverage check
uv run pytest app/tests/ --cov=app --cov-report=html --cov-report=term-missing
```

## Definition of Done

- [ ] All 102 new tests written
- [ ] All tests pass locally
- [ ] Coverage â‰¥ 80% (verified with `--cov-fail-under=80`)
- [ ] No skipped tests (except intentional @pytest.mark.skip with valid reason)
- [ ] No datetime deprecation warnings
- [ ] Ruff linting passes
- [ ] Pre-commit hooks pass
- [ ] CI/CD workflows green
- [ ] ROADMAP.md updated
- [ ] PR created with comprehensive description

---

**Total Test Count:** 570 â†’ 672 (+102)  
**Total Coverage:** 44.5% â†’ 80% (+35.5 pp)  
**Estimated Effort:** 2-3 days (16-24 hours)
